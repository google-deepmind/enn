{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KneoLFE258NW"
   },
   "source": [
    "# Run a pre-trained Epinet on ImageNet\n",
    "This demo shows how to run and evaluate a pre-trained *Epinet* on ImageNet. Epinet is a new ENN architecture that can supplement any conventional NN and be trained to estimate uncertainty.\n",
    "\n",
    "\n",
    "An epinet is a neural network with privileged access to inputs and outputs of activation units in the base network.\n",
    "A subset of these inputs and outputs, denoted by $\\phi_\\zeta(x)$, are taken as input to the epinet along with an epistemic index $z$.\n",
    "For epinet parameters $\\eta$, the epinet outputs $\\sigma_\\eta(\\phi_\\zeta(x), z)$.\n",
    "To produce an ENN, the output of the epinet is added to that of the base network, though with a \"stop gradient\" written $[[\\cdot]]$:\n",
    "\n",
    "$$ f_\\theta(x, z) = \\mu_\\zeta(x) + \\sigma_\\eta([[\\phi_\\zeta(x)]], z). $$\n",
    "\n",
    "\n",
    "We can visualize this network architecture:\n",
    "\n",
    "![epinet diagram](https://raw.githubusercontent.com/deepmind/enn/master/statics/images/epinet_new.png)\n",
    "\n",
    "For more details about Epinet, refer to the paper \n",
    "[Epistemic Neural Networks](https://arxiv.org/abs/2107.08924) (Osband et al., 2022).\n",
    "\n",
    "It's recommended to use `Runtime->Change Runtime Type` to pick a GPU for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "IGU1LEXZsplN",
    "outputId": "1e89c400-d08a-429c-ee1a-ad3e1a957134"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 DeepMind Technologies Limited. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "!git clone https://github.com/deepmind/enn.git\n",
    "!pip install -q enn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV8NEOiudvoZ"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "id": "qXOubWdlH9C0",
    "outputId": "d949eef3-68ca-48b2-8c4d-dd85da97e508"
   },
   "outputs": [],
   "source": [
    "#@title General imports\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#@title Development imports\n",
    "from typing import Callable, NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "\n",
    "from acme.utils.loggers.terminal import TerminalLogger\n",
    "import dataclasses\n",
    "import chex\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import dill\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "id": "EoyK1tD9Vjvo"
   },
   "outputs": [],
   "source": [
    "#@title ENN imports\n",
    "import enn\n",
    "from enn import datasets\n",
    "from enn.checkpoints import base as checkpoint_base\n",
    "from enn.networks.epinet import base as epinet_base\n",
    "from enn.checkpoints import utils\n",
    "from enn.checkpoints import imagenet\n",
    "from enn.checkpoints import catalog\n",
    "from enn import metrics as enn_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbswxUJc8fuA"
   },
   "source": [
    "## Load ImageNet dataset\n",
    "\n",
    "Our `enn` library provides functionalities in `enn/datasets` to load ImageNet, CIFAR10/100, and MNIST datasets. To load these datasets, you need to download that dataset into the default tensorflow dataset directory of `~/tensorflow_datasets/downloads/manual/`. \n",
    "\n",
    "In this colab, we want to evaluate Epinet on only one small batch of ImageNet test images. To this end, we provide a sample batch of size 100 at [https://storage.googleapis.com/dm-enn/processed_batch.npzs](https://storage.googleapis.com/dm-enn/processed_batch.npzs) which can be download as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0w5B1HVEto-P",
    "outputId": "d9b402b4-c03b-466c-b06b-50d87398d030"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/dm-enn/processed_batch.npzs --no-check-certificate\n",
    "with open('processed_batch.npzs', 'rb') as file:\n",
    "  batch = dill.load(file)\n",
    "images, labels = batch['images'], batch['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi3IzBqoSGkK"
   },
   "source": [
    "## Define a set of evaluation metrics\n",
    "\n",
    "Our `enn` library provides the set of known metrics for evaluating the performance of neural networks. These metrics which can be access from `enn/metrics` can be divided in three categories:\n",
    "\n",
    "\n",
    "1.   **Marginal**: includes metrics like accuracy and marginal negative log-likelihood (NLL) for evaluating marginal predictions.\n",
    "2.   **Joint**: includes metrics for evaluating joint predictions. \n",
    "3.   **Calibration**: includes metrics for calculating calibration error.\n",
    "\n",
    "Each metric takes logits and lables with the following shapes:\n",
    "  - logits: [num_enn_samples, batch_size, num_classes]\n",
    "  - labels: [batch_size, 1]\n",
    "\n",
    "`num_enn_samples` specifies the number of sample logits per input image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "gaoht3UJJb2m"
   },
   "outputs": [],
   "source": [
    "# Define a dict of metrics including `accuracy`, `marginal nll`, and `joint nll`.\n",
    "evaluation_metrics = {\n",
    "      'accuracy': enn_metrics.make_accuracy_calculator(),\n",
    "      'marginal nll': enn_metrics.make_nll_marginal_calculator(),\n",
    "      'joint nll': enn_metrics.make_nll_polyadic_calculator(tau=10, kappa=2),\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB26yDlmHxvj"
   },
   "source": [
    "## Load pre-trained Epinet\n",
    "\n",
    "Pre-trained Epinet can be accessed from `ImagenetModels` in `enn.checkpointing.catalog.py`. As of now, we provide pre-trained Epinet based on ResNet-50, ResNet-101, ResNet-152, and ResNet-200. In this colab, we want to load Epinet based on ResNet-50 which can be accessed from the checkpoint `RESNET_50_FINAL_EPINET`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "AMA2Stmjm_6O",
    "outputId": "67f14393-45e5-4b4c-dfcc-6757a56e5b50"
   },
   "outputs": [],
   "source": [
    "# Get the Epinet checkpoint\n",
    "epinet_resnet50_imagenet_ckpt = catalog.ImagenetModels.RESNET_50_FINAL_EPINET.value\n",
    "epinet_resnet50_imagenet_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0B8ytqQJFAN"
   },
   "source": [
    "From the checkpoint, we can recover an enn sampler, which is a function that takes a batch of images and one random key, and returns multiple sample logits per input image. To recover the enn sampler, we can use `make_epinet_sampler_from_checkpoint` (from `enn/checkpoints/utils.py`) which takes the checkpoint and also the number of sample logits we want per image (`num_enn_samples`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JCcrOudvI_t_"
   },
   "outputs": [],
   "source": [
    "# Set the number of sample logits per input image\n",
    "num_enn_samples = 100\n",
    "# Recover the enn sampler\n",
    "epinet_enn_sampler = utils.make_epinet_sampler_from_checkpoint(\n",
    "    epinet_resnet50_imagenet_ckpt,\n",
    "    num_enn_samples=num_enn_samples,)\n",
    "# Get the epinet logits\n",
    "key = jax.random.PRNGKey(seed=0)\n",
    "epinet_logits = epinet_enn_sampler(images, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "67UZuK97Ri-W",
    "outputId": "2e18a730-ec8b-491a-a4d3-15cca0bac3f9"
   },
   "outputs": [],
   "source": [
    "# epinet logits has shape [num_enn_sample, eval_batch_size, num_classes]\n",
    "epinet_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Ja9bC0Q7UVkM",
    "outputId": "6b91764d-71c1-40dd-fcd7-89ad4d3d27cb"
   },
   "outputs": [],
   "source": [
    "# Labels loaded from our dataset has shape [eval_batch_size,]. Our evaluation\n",
    "# metrics requires labels to have shape [eval_batch_size, 1].\n",
    "eval_labels = labels[:, None]\n",
    "# Evaluate \n",
    "epinet_results = {key: float(metric(epinet_logits, eval_labels)) \n",
    "                      for key, metric in evaluation_metrics.items()}\n",
    "epinet_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnY-iLAkW_u4"
   },
   "source": [
    "## Load pre-trained ResNet\n",
    "\n",
    "To have a better sense of how amazing Epinet is, we can compare its performance with a pretrained ResNet-50.\n",
    "\n",
    "Pre-trained ResNets can be accessed from `ImagenetModels` in `enn.checkpointing.catalog.py`. As of now, we provide pre-trained ResNet-50, ResNet-101, ResNet-152, and ResNet-200. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ocO9OQv4HIxn",
    "outputId": "b0c37332-fb7d-42bc-a395-0bf35c3a94a3"
   },
   "outputs": [],
   "source": [
    "# Get the ResNet-50 checkpoint\n",
    "resnet50_imagenet_ckpt = catalog.ImagenetModels.RESNET_50.value\n",
    "resnet50_imagenet_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sSq3q9ZXzy-"
   },
   "source": [
    "From the checkpoint, we can recover an enn sampler, which is a function that takes a batch of images and one random key, and returns multiple sample logits per input image. To recover the enn sampler for ResNet-50, we can use `make_enn_sampler_from_checkpoint` (from `enn/checkpoints/utils.py`) which takes the checkpoint and also the number of sample logits we want per image (`num_enn_samples`). Here we set `num_enn_samples=1`, as having `num_enn_samples > 1` just results in multiple similar sample logits per input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NixEickNXzFE"
   },
   "outputs": [],
   "source": [
    "# Set the number of sample logits per input image to 1\n",
    "num_enn_samples = 1\n",
    "# Recover the enn sampler\n",
    "resnet50_enn_sampler = utils.make_enn_sampler_from_checkpoint(\n",
    "    resnet50_imagenet_ckpt,\n",
    "    num_enn_samples=num_enn_samples,)\n",
    "# Get the epinet logits\n",
    "key = jax.random.PRNGKey(seed=0)\n",
    "resnet50_logits = resnet50_enn_sampler(images, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "9PNNqG4aY2cl",
    "outputId": "bb980423-ae4e-4932-c180-d317a86aff65"
   },
   "outputs": [],
   "source": [
    "# ResNet logits has shape [num_enn_sample, eval_batch_size, num_classes]\n",
    "resnet50_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rUb2u94_Y90P",
    "outputId": "dcf98ebe-81db-4d23-a01f-541619a03ba5"
   },
   "outputs": [],
   "source": [
    "# Labels loaded from our dataset has shape [eval_batch_size,]. Our evaluation\n",
    "# metrics requires labels to have shape [eval_batch_size, 1].\n",
    "eval_labels = labels[:, None]\n",
    "# Evaluate \n",
    "resnet50_results = {key: float(metric(resnet50_logits, eval_labels)) \n",
    "                      for key, metric in evaluation_metrics.items()}\n",
    "resnet50_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFhzjoYCawiY"
   },
   "source": [
    "## Compare Epinet and ResNet results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 112
    },
    "id": "gMvIsE4aa3Ex",
    "outputId": "6d92fce0-22bc-49ec-87f6-21833d575068"
   },
   "outputs": [],
   "source": [
    "# Make a dataframe of the results\n",
    "resnet50_results['model'] = 'resnet'\n",
    "epinet_results['model'] = 'epinet'\n",
    "df = pd.DataFrame([resnet50_results, epinet_results])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 422
    },
    "id": "kucVaz3Ya9h6",
    "outputId": "a68bf94b-46e5-4f8c-d4b8-0e4ae991dc54"
   },
   "outputs": [],
   "source": [
    "# Compare the results\n",
    "plt_df = pd.melt(df, id_vars=['model'], value_vars=evaluation_metrics.keys())\n",
    "p = (gg.ggplot(plt_df)\n",
    "    + gg.aes(x='model', y='value', fill='model') \n",
    "    + gg.geom_col()\n",
    "    + gg.facet_wrap('variable', scales='free',)\n",
    "    + gg.theme(figure_size=(14, 4), panel_spacing=0.7)\n",
    "    )\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "epinet_demo.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
