{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KneoLFE258NW"
   },
   "source": [
    "# Run a pre-trained Epinet on ImageNet\n",
    "This demo shows how to run and evaluate a pre-trained *Epinet* on ImageNet. Epinet is a new ENN architecture that can supplement any conventional NN and be trained to estimate uncertainty.\n",
    "\n",
    "\n",
    "An epinet is a neural network with privileged access to inputs and outputs of activation units in the base network.\n",
    "A subset of these inputs and outputs, denoted by $\\phi_\\zeta(x)$, are taken as input to the epinet along with an epistemic index $z$.\n",
    "For epinet parameters $\\eta$, the epinet outputs $\\sigma_\\eta(\\phi_\\zeta(x), z)$.\n",
    "To produce an ENN, the output of the epinet is added to that of the base network, though with a \"stop gradient\" written $[[\\cdot]]$:\n",
    "\n",
    "$$ f_\\theta(x, z) = \\mu_\\zeta(x) + \\sigma_\\eta([[\\phi_\\zeta(x)]], z). $$\n",
    "\n",
    "\n",
    "We can visualize this network architecture:\n",
    "\n",
    "![epinet diagram](https://raw.githubusercontent.com/deepmind/enn/master/statics/images/epinet_new.png)\n",
    "\n",
    "For more details about Epinet, refer to the paper \n",
    "[Epistemic Neural Networks](https://arxiv.org/abs/2107.08924) (Osband et al., 2022).\n",
    "\n",
    "It's recommended to use `Runtime->Change Runtime Type` to pick a GPU for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "IGU1LEXZsplN",
    "outputId": "1e89c400-d08a-429c-ee1a-ad3e1a957134"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 DeepMind Technologies Limited. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "!git clone https://github.com/deepmind/enn.git\n",
    "!pip install -q enn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV8NEOiudvoZ"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "id": "qXOubWdlH9C0",
    "outputId": "d949eef3-68ca-48b2-8c4d-dd85da97e508"
   },
   "outputs": [],
   "source": [
    "#@title General imports\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Development imports\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "import jax\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "id": "EoyK1tD9Vjvo"
   },
   "outputs": [],
   "source": [
    "#@title ENN imports\n",
    "from enn.networks.epinet import base as epinet_base\n",
    "from enn.checkpoints import utils\n",
    "from enn.checkpoints import catalog\n",
    "from enn import metrics as enn_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbswxUJc8fuA"
   },
   "source": [
    "## Load ImageNet dataset\n",
    "\n",
    "Our `enn` library provides functionalities in `enn/datasets` to load ImageNet, CIFAR10/100, and MNIST datasets. To load these datasets, you need to download that dataset into the default tensorflow dataset directory of `~/tensorflow_datasets/downloads/manual/`. \n",
    "\n",
    "In this colab, we want to evaluate Epinet on only one small batch of ImageNet test images. To this end, we provide a sample batch of size 100 at [https://storage.googleapis.com/dm-enn/processed_batch.npzs](https://storage.googleapis.com/dm-enn/processed_batch.npzs) which can be download as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0w5B1HVEto-P",
    "outputId": "d9b402b4-c03b-466c-b06b-50d87398d030"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/dm-enn/processed_batch.npzs --no-check-certificate\n",
    "with open('processed_batch.npzs', 'rb') as file:\n",
    "  batch = dill.load(file)\n",
    "images, labels = batch['images'], batch['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi3IzBqoSGkK"
   },
   "source": [
    "## Define a set of evaluation metrics\n",
    "\n",
    "Our `enn` library provides the set of known metrics for evaluating the performance of neural networks. These metrics which can be access from `enn/metrics` can be divided in three categories:\n",
    "\n",
    "\n",
    "1.   **Marginal**: includes metrics like accuracy and marginal negative log-likelihood (NLL) for evaluating marginal predictions.\n",
    "2.   **Joint**: includes metrics for evaluating joint predictions. \n",
    "3.   **Calibration**: includes metrics for calculating calibration error.\n",
    "\n",
    "Each metric takes logits and lables with the following shapes:\n",
    "  - logits: [num_enn_samples, batch_size, num_classes]\n",
    "  - labels: [batch_size, 1]\n",
    "\n",
    "`num_enn_samples` specifies the number of sample logits per input image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "gaoht3UJJb2m"
   },
   "outputs": [],
   "source": [
    "# Define a dict of metrics including `accuracy`, `marginal nll`, and `joint nll`.\n",
    "evaluation_metrics = {\n",
    "      'accuracy': enn_metrics.make_accuracy_calculator(),\n",
    "      'marginal nll': enn_metrics.make_nll_marginal_calculator(),\n",
    "      'joint nll': enn_metrics.make_nll_polyadic_calculator(tau=10, kappa=2),\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB26yDlmHxvj"
   },
   "source": [
    "## Load pre-trained Epinet\n",
    "\n",
    "Pre-trained Epinet can be accessed from `ImagenetModels` in `enn.checkpointing.catalog.py`. As of now, we provide pre-trained Epinet based on ResNet-50, ResNet-101, ResNet-152, and ResNet-200. In this colab, we want to load Epinet based on ResNet-50 which can be accessed from the checkpoint `RESNET_50_FINAL_EPINET`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "AMA2Stmjm_6O",
    "outputId": "67f14393-45e5-4b4c-dfcc-6757a56e5b50"
   },
   "outputs": [],
   "source": [
    "# Get the Epinet checkpoint\n",
    "epinet_resnet50_imagenet_ckpt = catalog.ImagenetModels.RESNET_50_FINAL_EPINET.value\n",
    "epinet_resnet50_imagenet_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0B8ytqQJFAN"
   },
   "source": [
    "From the checkpoint, we can recover an enn sampler, which is a function that takes a batch of images and one random key, and returns multiple sample logits per input image. To recover the enn sampler, we can use `make_epinet_sampler_from_checkpoint` (from `enn/checkpoints/utils.py`) which takes the checkpoint and also the number of sample logits we want per image (`num_enn_samples`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JCcrOudvI_t_"
   },
   "outputs": [],
   "source": [
    "# Set the number of sample logits per input image\n",
    "num_enn_samples = 100\n",
    "# Recover the enn sampler\n",
    "epinet_enn_sampler = utils.make_epinet_sampler_from_checkpoint(\n",
    "    epinet_resnet50_imagenet_ckpt,\n",
    "    num_enn_samples=num_enn_samples,)\n",
    "# Get the epinet logits\n",
    "key = jax.random.PRNGKey(seed=0)\n",
    "epinet_logits = epinet_enn_sampler(images, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "67UZuK97Ri-W",
    "outputId": "2e18a730-ec8b-491a-a4d3-15cca0bac3f9"
   },
   "outputs": [],
   "source": [
    "# epinet logits has shape [num_enn_sample, eval_batch_size, num_classes]\n",
    "epinet_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Ja9bC0Q7UVkM",
    "outputId": "6b91764d-71c1-40dd-fcd7-89ad4d3d27cb"
   },
   "outputs": [],
   "source": [
    "# Labels loaded from our dataset has shape [eval_batch_size,]. Our evaluation\n",
    "# metrics requires labels to have shape [eval_batch_size, 1].\n",
    "eval_labels = labels[:, None]\n",
    "# Evaluate \n",
    "epinet_results = {key: float(metric(epinet_logits, eval_labels)) \n",
    "                      for key, metric in evaluation_metrics.items()}\n",
    "epinet_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnY-iLAkW_u4"
   },
   "source": [
    "## Load pre-trained ResNet\n",
    "\n",
    "To have a better sense of how amazing Epinet is, we can compare its performance with a pretrained ResNet-50.\n",
    "\n",
    "Pre-trained ResNets can be accessed from `ImagenetModels` in `enn.checkpointing.catalog.py`. As of now, we provide pre-trained ResNet-50, ResNet-101, ResNet-152, and ResNet-200. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ocO9OQv4HIxn",
    "outputId": "b0c37332-fb7d-42bc-a395-0bf35c3a94a3"
   },
   "outputs": [],
   "source": [
    "# Get the ResNet-50 checkpoint\n",
    "resnet50_imagenet_ckpt = catalog.ImagenetModels.RESNET_50.value\n",
    "resnet50_imagenet_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sSq3q9ZXzy-"
   },
   "source": [
    "From the checkpoint, we can recover an enn sampler, which is a function that takes a batch of images and one random key, and returns multiple sample logits per input image. To recover the enn sampler for ResNet-50, we can use `make_enn_sampler_from_checkpoint` (from `enn/checkpoints/utils.py`) which takes the checkpoint and also the number of sample logits we want per image (`num_enn_samples`). Here we set `num_enn_samples=1`, as having `num_enn_samples > 1` just results in multiple similar sample logits per input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NixEickNXzFE"
   },
   "outputs": [],
   "source": [
    "# Set the number of sample logits per input image to 1\n",
    "num_enn_samples = 1\n",
    "# Recover the enn sampler\n",
    "resnet50_enn_sampler = utils.make_enn_sampler_from_checkpoint(\n",
    "    resnet50_imagenet_ckpt,\n",
    "    num_enn_samples=num_enn_samples,)\n",
    "# Get the epinet logits\n",
    "key = jax.random.PRNGKey(seed=0)\n",
    "resnet50_logits = resnet50_enn_sampler(images, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "9PNNqG4aY2cl",
    "outputId": "bb980423-ae4e-4932-c180-d317a86aff65"
   },
   "outputs": [],
   "source": [
    "# ResNet logits has shape [num_enn_sample, eval_batch_size, num_classes]\n",
    "resnet50_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rUb2u94_Y90P",
    "outputId": "dcf98ebe-81db-4d23-a01f-541619a03ba5"
   },
   "outputs": [],
   "source": [
    "# Labels loaded from our dataset has shape [eval_batch_size,]. Our evaluation\n",
    "# metrics requires labels to have shape [eval_batch_size, 1].\n",
    "eval_labels = labels[:, None]\n",
    "# Evaluate \n",
    "resnet50_results = {key: float(metric(resnet50_logits, eval_labels)) \n",
    "                      for key, metric in evaluation_metrics.items()}\n",
    "resnet50_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFhzjoYCawiY"
   },
   "source": [
    "## Compare Epinet and ResNet results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 112
    },
    "id": "gMvIsE4aa3Ex",
    "outputId": "6d92fce0-22bc-49ec-87f6-21833d575068"
   },
   "outputs": [],
   "source": [
    "# Make a dataframe of the results\n",
    "resnet50_results['model'] = 'resnet'\n",
    "epinet_results['model'] = 'epinet'\n",
    "df = pd.DataFrame([resnet50_results, epinet_results])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 422
    },
    "id": "kucVaz3Ya9h6",
    "outputId": "a68bf94b-46e5-4f8c-d4b8-0e4ae991dc54"
   },
   "outputs": [],
   "source": [
    "# Compare the results\n",
    "plt_df = pd.melt(df, id_vars=['model'], value_vars=evaluation_metrics.keys())\n",
    "p = (gg.ggplot(plt_df)\n",
    "    + gg.aes(x='model', y='value', fill='model') \n",
    "    + gg.geom_col()\n",
    "    + gg.facet_wrap('variable', scales='free',)\n",
    "    + gg.theme(figure_size=(14, 4), panel_spacing=0.7)\n",
    "    )\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "epinet_demo.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
